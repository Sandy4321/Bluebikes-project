{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## download Chromedriver based on Chrome Version\n",
    "## please put chromedriver.exe in the directory as \"C:\\Windows\\chromedriver.exe\"\n",
    "## pip install selenium\n",
    "## Preparing for scraping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling(driver):\n",
    "    ## the dateframe to store info\n",
    "    result=pd.DataFrame()\n",
    "    # Iterate through year, month, and day\n",
    "    for y in range(2017, 2020):\n",
    "        for m in range(1, 13):\n",
    "            for d in range(1, 32):\n",
    "                if (y==2019 and m==4 and d==2):\n",
    "                    return result\n",
    "                else:\n",
    "                    # Check if leap year\n",
    "                    if y%400 == 0:\n",
    "                        leap = True\n",
    "                    elif y%100 == 0:\n",
    "                        leap = False\n",
    "                    elif y%4 == 0:\n",
    "                        leap = True\n",
    "                    else:\n",
    "                        leap = False\n",
    "\n",
    "                    # check date of every month\n",
    "                    if (m == 2 and leap and d > 29):\n",
    "                        continue\n",
    "                    elif (m == 2 and d > 28):\n",
    "                        continue\n",
    "                    elif (m in [4, 6, 9, 11] and d > 30):\n",
    "                        continue\n",
    "\n",
    "                    # Open wunderground.com url\n",
    "                    url = \"https://www.wunderground.com/history/daily/us/ma/boston/KBOS/date/\"+str(y)+ \"-\" + str(m) + \"-\" + str(d)\n",
    "                    # https://www.wunderground.com/history/daily/us/ma/boston/KBOS/date/2019-7-2\n",
    "                    # https://www.wunderground.com/history/daily/us/ma/boston/KBOS/date/2019-5-2\n",
    "                    # https://www.wunderground.com/history/daily/us/ma/boston/KBOS/date/2019-4-2\n",
    "                    WebDriverWait(driver, 5)\n",
    "                    driver.get(url)\n",
    "                    tables = WebDriverWait(driver,30).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"table\")))\n",
    "                    for table in tables:\n",
    "                        newTable = pd.read_html(table.get_attribute('outerHTML'))\n",
    "                    if newTable:\n",
    "                        newTable[0]['Date']=np.repeat((str(y)+'-'+str(m).zfill(2)+'-'+str(d).zfill(2)),len(newTable[0]))\n",
    "                        result=result.append(newTable[0], ignore_index=True)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(driver):\n",
    "    i=0    \n",
    "    # Iterate through year, month, and day\n",
    "    for y in range(2017, 2020):\n",
    "        for m in range(1, 13):\n",
    "            for d in range(1, 32):\n",
    "                if (y==2019 and m==4 and d==2):\n",
    "                    return i\n",
    "                else:\n",
    "                    # Check if leap year\n",
    "                    if y%400 == 0:\n",
    "                        leap = True\n",
    "                    elif y%100 == 0:\n",
    "                        leap = False\n",
    "                    elif y%4 == 0:\n",
    "                        leap = True\n",
    "                    else:\n",
    "                        leap = False\n",
    "\n",
    "                    # Check if already gone through month\n",
    "                    if (m == 2 and leap and d > 29):\n",
    "                        continue\n",
    "                    elif (m == 2 and d > 28):\n",
    "                        continue\n",
    "                    elif (m in [4, 6, 9, 11] and d > 30):\n",
    "                        continue\n",
    "\n",
    "                    # Open wunderground.com url\n",
    "                    url = \"https://www.wunderground.com/history/daily/us/ma/boston/KBOS/date/\"+str(y)+ \"-\" + str(m) + \"-\" + str(d)\n",
    "                    i+=1               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minjie\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "821\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Windows\\chromedriver.exe\")\n",
    "weather=crawling(driver)\n",
    "print(test(driver)) ## sum up how many days \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.to_csv('Weather.csv', index=False)\n",
    "#weather=pd.read_csv('Weather.csv') #encoding=\"ISO-8859-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling1(driver):\n",
    "    ## the dateframe to store info\n",
    "    result=pd.DataFrame()\n",
    "    dates=[\"2017-3-13\",\"2017-6-5\",\"2017-12-2\",\"2018-3-23\",\"2018-6-5\",\"2018-8-23\",\"2018-11-30\",\"2019-3-12\",\"2019-3-13\"]\n",
    "    for date in dates:\n",
    "    # Open wunderground.com url\n",
    "        url = \"https://www.wunderground.com/history/daily/us/ma/boston/KBOS/date/\"+date\n",
    "        WebDriverWait(driver, 5)\n",
    "        driver.get(url)\n",
    "        tables = WebDriverWait(driver,30).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"table\")))\n",
    "        for table in tables:\n",
    "            newTable = pd.read_html(table.get_attribute('outerHTML'))\n",
    "        if newTable:\n",
    "            newTable[0]['Date']=np.repeat((date),len(newTable[0]))\n",
    "            result=result.append(newTable[0], ignore_index=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Windows\\chromedriver.exe\")\n",
    "weather2=crawling1(driver)\n",
    "driver.quit()\n",
    "weather2.to_csv('Weather2', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
